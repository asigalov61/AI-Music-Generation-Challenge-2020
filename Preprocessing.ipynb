{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "from data.abc import ABCPreProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be preprocessing two types of data --> **ABC Notation** data and **Audio** data\n",
    "\n",
    "### ABC Notation Data\n",
    "\n",
    "- Strip away **Tune body**, **key**, **meter**, **rhythm** and store all other fields of an ABC track as metadata\n",
    "- Use key and meter as conditioning symbols when generating a tune\n",
    "- Tokenize according to vocabulary of musical transcription tokens\n",
    "\n",
    "- Create a TFRecord Dataset consisting sequence examples like --> **[ tune, meter, key, rhythm ]**\n",
    "\n",
    "### Audio Data\n",
    "- Turning the full audio into short examples (4 seconds by default, but adjustable with flags)\n",
    "- Inferring the fundamental frequency (or \"pitch\") with CREPE\n",
    "- Computing the loudness features\n",
    "\n",
    "- Create TFRecord Dataset consisting sequence examples like --> **[ Audio, f0_feature, loudness_feature ]**\n",
    "\n",
    "#### Each tune be indexed such that using its ID, we can find its ABC Notation as well as related audio files\n",
    "- A tune can be associated with more than one audio file (Different audio lengths!!)\n",
    "\n",
    "At the end of the file, we should merge both the datasets, to obtain a single TFRecord file containing preprocessed ABC data and preprocessed audio files indexed according to the different tunes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize common variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mention the path to the datastore\n",
    "BASE_DIR = \"/home/richhiey/Desktop/workspace/projects/AI_Music_Challenge_2020\"\n",
    "\n",
    "# BASE_DIR = \"/home/rithomas/project/AI-Music-Generation-Challenge-2020/\"\n",
    "ABC_DATA_DIR = os.path.join(BASE_DIR, \"datasets\", \"abc_data\")\n",
    "ABC_TFRECORD_DIR = os.path.join(BASE_DIR, \"tfrecords\", \"abc\")\n",
    "PROCESSED_ABC_FILENAME = 'processed-abc-files'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing - ABC Notation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To understand the underlying distribution of tunes in Irish music, it can be helpful to visualize the following quantities:\n",
    "- Maximum length of tunes in each category\n",
    "- Number of tunes in each category\n",
    "- Number of tunes in each key\n",
    "- Number of tunes in each meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/31721 [00:00<1:23:50,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "ABC Extended Vocabulary:\n",
      "{'word_to_idx': {'C,': '1', '^C,': '2', 'D,': '3', '^D,': '4', 'E,': '5', 'F,': '6', '^F,': '7', 'G,': '8', '^G,': '9', 'A,': '10', '^A,': '11', 'B,': '12', 'C': '13', '^C': '14', 'D': '15', '^D': '16', 'E': '17', 'F': '18', '^F': '19', 'G': '20', '^G': '21', 'A': '22', '^A': '23', 'B': '24', 'c': '25', '^c': '26', 'd': '27', '^d': '28', 'e': '29', 'f': '30', '^f': '31', 'g': '32', '^g': '33', 'a': '34', '^a': '35', 'b': '36', \"c'\": '37', \"^c'\": '38', \"d'\": '39', \"^d'\": '40', \"e'\": '41', \"f'\": '42', \"g'\": '43', \"^g'\": '44', \"a'\": '45', \"^a'\": '46', \"B'\": '47', '_C,': '48', '_D,': '49', '_E,': '50', '_G,': '51', '_A,': '52', '_B,': '53', '_C': '54', '_D': '55', '_E': '56', '_G': '57', '_A': '58', '_B': '59', '_c': '60', '_d': '61', '_e': '62', '_g': '63', '_a': '64', '_b': '65', \"_c'\": '66', \"_d'\": '67', \"_e'\": '68', \"_g'\": '69', \"_a'\": '70', \"_b'\": '71', '=C,': '72', '=E,': '73', '=F,': '74', '=G,': '75', '=A,': '76', '=B,': '77', '=C': '78', '=D': '79', '=E': '80', '=F': '81', '=G': '82', '=A': '83', '=B': '84', '=c': '85', '=d': '86', '=e': '87', '=f': '88', '=g': '89', '=a': '90', '=b': '91', \"=c'\": '92', \"=d'\": '93', \"=e'\": '94', \"=f'\": '95', \"=g'\": '96', \"=a'\": '97', \"=b'\": '98', 'z': '99', '|': '100', '|:': '101', ':|': '102', '|]': '103', '||': '104', '[|': '105', '::': '106', '|1': '107', '|2': '108', '(2': '109', '(3': '110', '(4': '111', '(5': '112', '(6': '113', '(7': '114', '(9': '115', '/': '116', '/2': '117', '/3': '118', '/4': '119', '/8': '120', '2': '121', '3': '122', '4': '123', '5': '124', '6': '125', '7': '126', '8': '127', '9': '128', '12': '129', '16': '130', '3/4': '131', '3/2': '132', '5/2': '133', '7/2': '134', '2>': '135', '2<': '136', '/2>': '137', '/2<': '138', '4>': '139', '<': '140', '>': '141', '<s>': '142', '</s>': '143', 'M:9/8': '144', 'M:4/4': '145', 'M:6/8': '146', 'M:3/4': '147', 'M:2/4': '148', 'M:3/2': '149', 'M:12/8': '150', 'K:Gmajor': '151', 'K:Bminor': '152', 'K:Ddorian': '153', 'K:Amixolydian': '154', 'K:Dmajor': '155', 'K:Edorian': '156', 'K:Emajor': '157', 'K:Eminor': '158', 'K:Dminor': '159', 'K:Adorian': '160', 'K:Fmajor': '161', 'K:Gdorian': '162', 'K:Gminor': '163', 'K:Cmajor': '164', 'K:Amajor': '165', 'K:Dmixolydian': '166', 'K:Aminor': '167', 'K:Fdorian': '168', 'K:Emixolydian': '169', 'K:Bmixolydian': '170', 'K:Gmixolydian': '171', 'K:Bdorian': '172'}, 'idx_to_word': {'1': 'C,', '2': '^C,', '3': 'D,', '4': '^D,', '5': 'E,', '6': 'F,', '7': '^F,', '8': 'G,', '9': '^G,', '10': 'A,', '11': '^A,', '12': 'B,', '13': 'C', '14': '^C', '15': 'D', '16': '^D', '17': 'E', '18': 'F', '19': '^F', '20': 'G', '21': '^G', '22': 'A', '23': '^A', '24': 'B', '25': 'c', '26': '^c', '27': 'd', '28': '^d', '29': 'e', '30': 'f', '31': '^f', '32': 'g', '33': '^g', '34': 'a', '35': '^a', '36': 'b', '37': \"c'\", '38': \"^c'\", '39': \"d'\", '40': \"^d'\", '41': \"e'\", '42': \"f'\", '43': \"g'\", '44': \"^g'\", '45': \"a'\", '46': \"^a'\", '47': \"B'\", '48': '_C,', '49': '_D,', '50': '_E,', '51': '_G,', '52': '_A,', '53': '_B,', '54': '_C', '55': '_D', '56': '_E', '57': '_G', '58': '_A', '59': '_B', '60': '_c', '61': '_d', '62': '_e', '63': '_g', '64': '_a', '65': '_b', '66': \"_c'\", '67': \"_d'\", '68': \"_e'\", '69': \"_g'\", '70': \"_a'\", '71': \"_b'\", '72': '=C,', '73': '=E,', '74': '=F,', '75': '=G,', '76': '=A,', '77': '=B,', '78': '=C', '79': '=D', '80': '=E', '81': '=F', '82': '=G', '83': '=A', '84': '=B', '85': '=c', '86': '=d', '87': '=e', '88': '=f', '89': '=g', '90': '=a', '91': '=b', '92': \"=c'\", '93': \"=d'\", '94': \"=e'\", '95': \"=f'\", '96': \"=g'\", '97': \"=a'\", '98': \"=b'\", '99': 'z', '100': '|', '101': '|:', '102': ':|', '103': '|]', '104': '||', '105': '[|', '106': '::', '107': '|1', '108': '|2', '109': '(2', '110': '(3', '111': '(4', '112': '(5', '113': '(6', '114': '(7', '115': '(9', '116': '/', '117': '/2', '118': '/3', '119': '/4', '120': '/8', '121': '2', '122': '3', '123': '4', '124': '5', '125': '6', '126': '7', '127': '8', '128': '9', '129': '12', '130': '16', '131': '3/4', '132': '3/2', '133': '5/2', '134': '7/2', '135': '2>', '136': '2<', '137': '/2>', '138': '/2<', '139': '4>', '140': '<', '141': '>', '142': '<s>', '143': '</s>', '144': 'M:9/8', '145': 'M:4/4', '146': 'M:6/8', '147': 'M:3/4', '148': 'M:2/4', '149': 'M:3/2', '150': 'M:12/8', '151': 'K:Gmajor', '152': 'K:Bminor', '153': 'K:Ddorian', '154': 'K:Amixolydian', '155': 'K:Dmajor', '156': 'K:Edorian', '157': 'K:Emajor', '158': 'K:Eminor', '159': 'K:Dminor', '160': 'K:Adorian', '161': 'K:Fmajor', '162': 'K:Gdorian', '163': 'K:Gminor', '164': 'K:Cmajor', '165': 'K:Amajor', '166': 'K:Dmixolydian', '167': 'K:Aminor', '168': 'K:Fdorian', '169': 'K:Emixolydian', '170': 'K:Bmixolydian', '171': 'K:Gmixolydian', '172': 'K:Bdorian'}}\n",
      "---------------------------------------------------------\n",
      "Preparing to save extracted information into a TFRecord file at /home/richhiey/Desktop/workspace/projects/AI_Music_Challenge_2020/tfrecords/abc/processed-abc-files.tfrecord ...\n",
      "Creating TFRecord File ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 75/31721 [00:06<49:03, 10.75it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5071d8f482e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---------------------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtfrecord_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_as_tfrecord_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/workspace/projects/AI_Music_Challenge_2020/AI-Music-Generation-Challenge-2020/data/abc.py\u001b[0m in \u001b[0;36msave_as_tfrecord_dataset\u001b[0;34m(self, tokenizer)\u001b[0m\n\u001b[1;32m    129\u001b[0m                                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'CONSTANT'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                             ),\n\u001b[0;32m--> 131\u001b[0;31m                             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_tune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m                         )\n\u001b[1;32m    133\u001b[0m                         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/projects/AI_Music_Challenge_2020/AI-Music-Generation-Challenge-2020/data/abc.py\u001b[0m in \u001b[0;36mserialize_example\u001b[0;34m(_input, _output, tune_length)\u001b[0m\n\u001b[1;32m    333\u001b[0m                     feature = [\n\u001b[1;32m    334\u001b[0m                         tf.train.Feature(\n\u001b[0;32m--> 335\u001b[0;31m                             \u001b[0mint64_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt64List\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m                         )\n\u001b[1;32m    337\u001b[0m                     ]  \n",
      "\u001b[0;32m~/Desktop/workspace/projects/AI_Music_Challenge_2020/ai_music_venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6929\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6930\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6931\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6932\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/projects/AI_Music_Challenge_2020/ai_music_venv/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/projects/AI_Music_Challenge_2020/ai_music_venv/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0mend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m       \u001b[0mstrides\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mshrink_axis_mask\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "preprocessor = ABCPreProcessor(ABC_TFRECORD_DIR, PROCESSED_ABC_FILENAME)\n",
    "#json_path = preprocessor.process(ABC_DATA_DIR)\n",
    "tokenizer = preprocessor.create_tokenizer()\n",
    "print('---------------------------------------------------------')\n",
    "print('ABC Extended Vocabulary:')\n",
    "print(tokenizer.return_vocabulary())\n",
    "print('---------------------------------------------------------')\n",
    "tfrecord_path = preprocessor.save_as_tfrecord_dataset(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
