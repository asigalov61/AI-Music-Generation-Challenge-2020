{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from data.abc import ABCPreProcessor\n",
    "from models.symbolic.transformer import FolkTransformer\n",
    "from models.symbolic.rnn import FolkLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base directory paths and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mention the path to the datastore\n",
    "BASE_DIR = \"/home/rithomas/project/AI-Music-Generation-Challenge-2020/\"\n",
    "TFRECORD_PATH = os.path.join(\"/home/rithomas/cache\", \"ABC\")\n",
    "PROCESSED_ABC_FILENAME = 'processed-abc-files'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets and prepare for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOUBLE_JIGS_DATASET_DIR = os.path.join(TFRECORD_PATH, 'Double-Jigs')\n",
    "SIXEIGHT_METER_TUNES_DIR = os.path.join(TFRECORD_PATH, '6-8-Meter')\n",
    "THESESSION_TUNES_DIR = os.path.join(TFRECORD_PATH, 'TheSession-Data')\n",
    "\n",
    "preprocessor = ABCPreProcessor(DOUBLE_JIGS_DATASET_DIR, PROCESSED_ABC_FILENAME)\n",
    "double_jigs_dataset = preprocessor.load_tfrecord_dataset()\n",
    "\n",
    "preprocessor = ABCPreProcessor(SIXEIGHT_METER_TUNES_DIR, PROCESSED_ABC_FILENAME)\n",
    "sixeight_meter_tunes_dataset = preprocessor.load_tfrecord_dataset()\n",
    "\n",
    "preprocessor = ABCPreProcessor(THESESSION_TUNES_DIR, PROCESSED_ABC_FILENAME)\n",
    "thesession_dataset = preprocessor.load_tfrecord_dataset()\n",
    "\n",
    "# Same preprocessing for all datasets, so reuse preprocessor\n",
    "batch_size = 64\n",
    "double_jigs_dataset = preprocessor.prepare_dataset(double_jigs_dataset, 16)\n",
    "sixeight_meter_tunes_dataset = preprocessor.prepare_dataset(sixeight_meter_tunes_dataset, batch_size)\n",
    "thesession_dataset = preprocessor.prepare_dataset(thesession_dataset, batch_size)\n",
    "\n",
    "# Data dims same for all since same preprocessing is applied\n",
    "data_dims_1 = preprocessor.get_data_dimensions(DOUBLE_JIGS_DATASET_DIR)\n",
    "data_dims_2 = preprocessor.get_data_dimensions(SIXEIGHT_METER_TUNES_DIR)\n",
    "data_dims_3 = preprocessor.get_data_dimensions(THESESSION_TUNES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LSTM and Transformer model instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLK_LSTM_1_DIR = os.path.join(BASE_DIR, 'configs', 'lstm_double_jigs')\n",
    "FOLK_LSTM_2_DIR = os.path.join(BASE_DIR, 'configs', 'lstm_6_8_meter')\n",
    "FOLK_LSTM_3_DIR = os.path.join(BASE_DIR, 'configs', 'lstm_thesession')\n",
    "lstm_1 = FolkLSTM(FOLK_LSTM_1_DIR, data_dims_1, DOUBLE_JIGS_DATASET_DIR)\n",
    "lstm_2 = FolkLSTM(FOLK_LSTM_2_DIR, data_dims_2, SIXEIGHT_METER_TUNES_DIR)\n",
    "lstm_3 = FolkLSTM(FOLK_LSTM_3_DIR, data_dims_3, THESESSION_TUNES_DIR)\n",
    "\n",
    "FOLK_TRANSFORMER_1_DIR = os.path.join(BASE_DIR, 'configs', 'transformer_double_jigs')\n",
    "FOLK_TRANSFORMER_2_DIR = os.path.join(BASE_DIR, 'configs', 'transformer_6_8_meter')\n",
    "FOLK_TRANSFORMER_3_DIR = os.path.join(BASE_DIR, 'configs', 'transformer_thesession')      \n",
    "transformer_1 = FolkTransformer(FOLK_TRANSFORMER_1_DIR, data_dims_1, DOUBLE_JIGS_DATASET_DIR)\n",
    "transformer_2 = FolkTransformer(FOLK_TRANSFORMER_2_DIR, data_dims_2, SIXEIGHT_METER_TUNES_DIR)\n",
    "transformer_3 = FolkTransformer(FOLK_TRANSFORMER_3_DIR, data_dims_3, THESESSION_TUNES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM 1 - Training on double jigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lstm_1.get_configs())\n",
    "lstm_1.train(double_jigs_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM 2 - Training on tunes in 6/8 Meter from TheSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lstm_2.get_configs())\n",
    "lstm_2.train(sixeight_meter_tunes_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM 3 - Training on all tunes from TheSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lstm_3.get_configs())\n",
    "lstm_3.train(thesession_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer 1 - Training on double jigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformer_1.get_configs())\n",
    "transformer_1.train(double_jigs_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer 2 - Training on tunes in 6/8 Meter from TheSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformer_2.get_configs())\n",
    "transformer_2.train(sixeight_meter_tunes_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer 3 - Training on all tunes from TheSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformer_3.get_configs())\n",
    "transformer_3.train(thesession_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_music_challenge",
   "language": "python",
   "name": "ai_music_challenge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
